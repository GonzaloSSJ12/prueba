<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Traductor de Señas en Tiempo Real</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/knn-classifier"></script>
  <style>
    body {
      display: flex;
      flex-direction: column;
      align-items: center;
      margin: 0;
      padding: 0;
      background: #f0f0f0;
      font-family: sans-serif;
      min-height: 100vh;
    }
    .camera-container {
      position: relative;
      width: 100%;
      max-width: 640;
      margin-top: 20px;
    }
    #video, #overlay {
      width: 100%;
      height: auto;
      transform: scaleX(-1);
    }
    #overlay {
      position: absolute;
      top: 0;
      left: 0;
      pointer-events: none;
    }
    .controls {
      width: 100%;
      max-width: 640px;
      padding: 10px;
      box-sizing: border-box;
    }
    input, button {
      width: 100%;
      padding: 12px;
      margin: 5px 0;
      font-size: 1em;
      border: 1px solid #ddd;
      border-radius: 5px;
    }
    button {
      background: #007bff;
      color: white;
      border: none;
      cursor: pointer;
    }
    button:disabled {
      background: #6c757d;
    }
    #progress {
      width: 100%;
      height: 20px;
      background: #ddd;
      margin: 10px 0;
      display: none;
      border-radius: 5px;
      overflow: hidden;
    }
    #progress-bar {
      width: 0%;
      height: 100%;
      background: #28a745;
      transition: width 0.3s;
    }
    #translations {
      width: 100%;
      max-width: 640px;
      padding: 10px;
      box-sizing: border-box;
      font-size: 1.2em;
      min-height: 100px;
      background: white;
      border-radius: 5px;
      margin: 10px;
    }
    @media (max-width: 640px) {
      #video, #overlay {
        height: 60vh;
        object-fit: cover;
      }
    }
  </style>
</head>
<body>
  <h1>Traductor de Señas</h1>
  <div class="camera-container">
    <video id="video" autoplay muted playsinline></video>
    <canvas id="overlay"></canvas>
  </div>
  
  <div class="controls">
    <input type="text" id="gestureName" placeholder="Nombre del gesto">
    <button onclick="startTraining()" id="trainBtn">Entrenar Nueva Seña</button>
    <button onclick="toggleDetection()" id="detectBtn">Iniciar Detección</button>
    <button onclick="clearTranslations()" id="clearBtn">Limpiar Traducciones</button>
    <div id="progress">
      <div id="progress-bar"></div>
    </div>
  </div>
  
  <div id="translations"></div>

  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>

  <script>
    let classifier = knnClassifier.create();
    let isTraining = false;
    let isDetecting = false;
    let currentGesture = null;
    let trainingStartTime = 0;
    let lastDetection = '';

    const videoElement = document.getElementById('video');
    const canvasElement = document.getElementById('overlay');
    const translationsEl = document.getElementById('translations');
    const progressBar = document.getElementById('progress-bar');
    const progressContainer = document.getElementById('progress');
    const ctx = canvasElement.getContext('2d');

    function resizeCanvas() {
      canvasElement.width = videoElement.videoWidth;
      canvasElement.height = videoElement.videoHeight;
    }

    videoElement.addEventListener('loadedmetadata', resizeCanvas);
    window.addEventListener('resize', resizeCanvas);

    const hands = new Hands({
      locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
    });

    hands.setOptions({
      maxNumHands: 2,
      modelComplexity: 1,
      minDetectionConfidence: 0.8,
      minTrackingConfidence: 0.7
    });

    hands.onResults(results => {
      resizeCanvas(); // Asegura que canvas se mantenga sincronizado
      ctx.clearRect(0, 0, canvasElement.width, canvasElement.height);
      ctx.save();
      ctx.scale(1, 1);
      ctx.drawImage(videoElement, 0, 0, canvasElement.width, canvasElement.height);
      ctx.restore();

      if (results.multiHandLandmarks) {
        results.multiHandLandmarks.forEach((landmarks, i) => {
          const handLabel = results.multiHandedness[i].label.toLowerCase(); // 'left' o 'right'

          window.drawConnectors(ctx, landmarks, window.HAND_CONNECTIONS, {
            color: handLabel === 'left' ? '#00AAFF' : '#00FF00',
            lineWidth: 2
          });
          window.drawLandmarks(ctx, landmarks, { color: '#FF0000', lineWidth: 1 });

          // Dibujar "L" o "R" junto a la muñeca
          const wrist = landmarks[0];
          const label = handLabel === 'left' ? 'L' : 'R';
          const x = wrist.x * canvasElement.width + 10;
          const y = wrist.y * canvasElement.height + 5;

          ctx.save();
          ctx.fillStyle = 'black';
          ctx.font = '20px Arial';
          ctx.fillText(label, x, y);
          ctx.restore();

          if (isTraining || isDetecting) {
            processGesture(landmarks, handLabel);
          }
        });
      }
    });

    const camera = new Camera(videoElement, {
      onFrame: async () => {
        await hands.send({ image: videoElement });
      },
      width: 640,
      height: 480
    });
    camera.start();

    async function processGesture(landmarks, handLabel) {
      const features = getNormalizedFeatures(landmarks);
      const labelWithHand = `${currentGesture || ''}_${handLabel}`;

      if (isTraining) {
        const elapsed = Date.now() - trainingStartTime;
        const progress = Math.min(elapsed / 3000 * 100, 100);
        progressBar.style.width = `${progress}%`;

        if (elapsed <= 3000) {
          classifier.addExample(tf.tensor2d(features, [1, 63]), labelWithHand);
        }
      }

      if (isDetecting) {
        const result = await classifier.predictClass(tf.tensor2d(features, [1, 63]));
        if (result.confidences[result.label] > 0.9) {
          handleDetection(result.label);
        }
      }
    }

    function getNormalizedFeatures(landmarks) {
      const wrist = landmarks[0];
      const relativeLandmarks = landmarks.map(l => ({
        x: l.x - wrist.x,
        y: l.y - wrist.y,
        z: l.z - wrist.z
      }));

      const maxVal = Math.max(
        ...relativeLandmarks.flatMap(l => [Math.abs(l.x), Math.abs(l.y), Math.abs(l.z)])
      );

      return relativeLandmarks.flatMap(l => [
        l.x / maxVal,
        l.y / maxVal,
        l.z / maxVal
      ]);
    }

    async function startTraining() {
      currentGesture = document.getElementById('gestureName').value.trim();
      if (!currentGesture) return alert('Ingrese nombre del gesto');

      const btn = document.getElementById('trainBtn');
      btn.disabled = true;
      document.getElementById('gestureName').value = '';

      progressContainer.style.display = 'block';
      progressBar.style.width = '0%';
      isTraining = true;
      trainingStartTime = Date.now();

      setTimeout(() => {
        isTraining = false;
        progressContainer.style.display = 'none';
        btn.disabled = false;
        translationsEl.innerHTML += `<div>✅ ${currentGesture} entrenado (izq./der.)</div>`;
        saveModel();
      }, 3000);
    }

    function handleDetection(gesture) {
      if (gesture !== lastDetection) {
        translationsEl.innerHTML += `<div>${gesture}</div>`;
        lastDetection = gesture;
        translationsEl.scrollTop = translationsEl.scrollHeight;
      }
    }

    function toggleDetection() {
      isDetecting = !isDetecting;
      document.getElementById('detectBtn').textContent = 
        isDetecting ? 'Detener Detección' : 'Iniciar Detección';
    }

    function clearTranslations() {
      translationsEl.innerHTML = '';
      lastDetection = '';
    }

    async function saveModel() {
      const dataset = classifier.getClassifierDataset();
      const datasetObj = {};
      Object.keys(dataset).forEach(key => {
        datasetObj[key] = Array.from(dataset[key].dataSync());
      });
      localStorage.setItem('gestureModel', JSON.stringify(datasetObj));
    }

    async function loadModel() {
      const savedModel = localStorage.getItem('gestureModel');
      if (savedModel) {
        const dataset = JSON.parse(savedModel);
        Object.keys(dataset).forEach(key => {
          const tensor = tf.tensor2d(dataset[key], [dataset[key].length / 63, 63]);
          classifier.addDataset(tensor, key);
        });
      }
    }

    loadModel();
  </script>
</body>
</html>
