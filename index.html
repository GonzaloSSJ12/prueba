<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Traductor de Señas con Detección Facial</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/knn-classifier"></script>
  <style>
    body {
      display: flex;
      flex-direction: column;
      align-items: center;
      margin: 0;
      padding: 0;
      background: #f0f0f0;
      font-family: sans-serif;
      min-height: 100vh;
    }
    .camera-container {
      position: relative;
      width: 100%;
      max-width: 640px;
      margin-top: 20px;
    }
    #video, #overlay {
      width: 100%;
      height: auto;
      transform: scaleX(-1);
    }
    #overlay {
      position: absolute;
      top: 0;
      left: 0;
      pointer-events: none;
    }
    .controls {
      width: 100%;
      max-width: 640px;
      padding: 10px;
      box-sizing: border-box;
    }
    input, button {
      width: 100%;
      padding: 12px;
      margin: 5px 0;
      font-size: 1em;
      border: 1px solid #ddd;
      border-radius: 5px;
    }
    button {
      background: #007bff;
      color: white;
      border: none;
      cursor: pointer;
    }
    button:disabled {
      background: #6c757d;
    }
    #progress {
      width: 100%;
      height: 20px;
      background: #ddd;
      margin: 10px 0;
      display: none;
      border-radius: 5px;
      overflow: hidden;
    }
    #progress-bar {
      width: 0%;
      height: 100%;
      background: #28a745;
      transition: width 0.3s;
    }
    #translations {
      width: 100%;
      max-width: 640px;
      padding: 10px;
      box-sizing: border-box;
      font-size: 1.2em;
      min-height: 100px;
      background: white;
      border-radius: 5px;
      margin: 10px;
    }
    .face-box {
      position: absolute;
      border: 2px solid #ff0000;
      background: rgba(255, 0, 0, 0.1);
    }
  </style>
</head>
<body>
  <h1>Traductor de Señas + Detección Facial</h1>
  <div class="camera-container">
    <video id="video" autoplay muted playsinline></video>
    <canvas id="overlay"></canvas>
  </div>
  
  <div class="controls">
    <input type="text" id="gestureName" placeholder="Nombre del gesto">
    <button onclick="startTraining()" id="trainBtn">Entrenar Nueva Seña</button>
    <button onclick="toggleDetection()" id="detectBtn">Iniciar Detección</button>
    <button onclick="clearTranslations()" id="clearBtn">Limpiar Traducciones</button>
    <div id="progress">
      <div id="progress-bar"></div>
    </div>
  </div>
  
  <div id="translations"></div>

  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/face_detection.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>

  <script>
    let classifier = knnClassifier.create();
    let isTraining = false;
    let isDetecting = false;
    let currentGesture = null;
    let trainingStartTime = 0;
    let lastDetection = '';
    
    const videoElement = document.getElementById('video');
    const canvasElement = document.getElementById('overlay');
    const translationsEl = document.getElementById('translations');
    const progressBar = document.getElementById('progress-bar');
    const progressContainer = document.getElementById('progress');

    // Configurar canvas
    canvasElement.width = videoElement.offsetWidth;
    canvasElement.height = videoElement.offsetHeight;
    const ctx = canvasElement.getContext('2d');

    // Configurar detectores
    const hands = new Hands({
      locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
    });
    
    const faceDetection = new FaceDetection({
      locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/${file}`
    });

    // Configurar opciones
    hands.setOptions({
      maxNumHands: 1,
      modelComplexity: 1,
      minDetectionConfidence: 0.8,
      minTrackingConfidence: 0.7
    });

    faceDetection.setOptions({
      model: 'short',
      minDetectionConfidence: 0.5
    });

    // Función combinada de dibujo
    function drawCombinedResults(handsResults, faceResults) {
      ctx.clearRect(0, 0, canvasElement.width, canvasElement.height);
      ctx.drawImage(videoElement, 0, 0, canvasElement.width, canvasElement.height);

      // Dibujar manos
      if (handsResults.multiHandLandmarks) {
        handsResults.multiHandLandmarks.forEach(landmarks => {
          window.drawConnectors(ctx, landmarks, window.HAND_CONNECTIONS, 
            {color: '#00FF00', lineWidth: 2});
          window.drawLandmarks(ctx, landmarks, {color: '#FF0000', lineWidth: 1});
        });
      }

      // Dibujar rostros
      if (faceResults.detections) {
        faceResults.detections.forEach(detection => {
          const bb = detection.boundingBox;
          ctx.beginPath();
          ctx.rect(
            bb.xCenter * canvasElement.width - bb.width * canvasElement.width / 2,
            bb.yCenter * canvasElement.height - bb.height * canvasElement.height / 2,
            bb.width * canvasElement.width,
            bb.height * canvasElement.height
          );
          ctx.strokeStyle = '#FF0000';
          ctx.lineWidth = 2;
          ctx.stroke();
        });
      }
    }

    // Configurar cámaras
    const camera = new Camera(videoElement, {
      onFrame: async () => {
        await Promise.all([
          hands.send({ image: videoElement }),
          faceDetection.send({ image: videoElement })
        ]);
      },
      width: canvasElement.width,
      height: canvasElement.height
    });

    hands.onResults(results => {
      faceDetection.send({ image: videoElement }).then(faceResults => {
        drawCombinedResults(results, faceResults);
        if (isTraining || isDetecting) processGesture(results.multiHandLandmarks[0]);
      });
    });

    async function processGesture(landmarks) {
      if (!landmarks) return;
      
      const features = getNormalizedFeatures(landmarks);
      
      if (isTraining) {
        const elapsed = Date.now() - trainingStartTime;
        const progress = Math.min(elapsed / 3000 * 100, 100);
        progressBar.style.width = `${progress}%`;
        
        if (elapsed <= 3000) {
          classifier.addExample(tf.tensor2d(features, [1, 63]), currentGesture);
        }
      }
      
      if (isDetecting) {
        const result = await classifier.predictClass(tf.tensor2d(features, [1, 63]));
        if (result.confidences[result.label] > 0.9) {
          handleDetection(result.label);
        }
      }
    }

    function getNormalizedFeatures(landmarks) {
      const wrist = landmarks[0];
      const relativeLandmarks = landmarks.map(l => ({
        x: l.x - wrist.x,
        y: l.y - wrist.y,
        z: l.z - wrist.z
      }));
      
      const maxVal = Math.max(
        ...relativeLandmarks.flatMap(l => [Math.abs(l.x), Math.abs(l.y), Math.abs(l.z)])
      );
      
      return relativeLandmarks.flatMap(l => [
        l.x / maxVal,
        l.y / maxVal,
        l.z / maxVal
      ]);
    }

    async function startTraining() {
      currentGesture = document.getElementById('gestureName').value.trim();
      if (!currentGesture) return alert('Ingrese nombre del gesto');
      
      const btn = document.getElementById('trainBtn');
      btn.disabled = true;
      document.getElementById('gestureName').value = '';
      
      progressContainer.style.display = 'block';
      progressBar.style.width = '0%';
      isTraining = true;
      trainingStartTime = Date.now();
      
      setTimeout(() => {
        isTraining = false;
        progressContainer.style.display = 'none';
        btn.disabled = false;
        translationsEl.innerHTML += `<div>✅ ${currentGesture} entrenado!</div>`;
        saveModel();
      }, 3000);
    }

    function handleDetection(gesture) {
      if (gesture !== lastDetection) {
        translationsEl.innerHTML += `<div>${new Date().toLocaleTimeString()}: ${gesture}</div>`;
        lastDetection = gesture;
        translationsEl.scrollTop = translationsEl.scrollHeight;
      }
    }

    function toggleDetection() {
      isDetecting = !isDetecting;
      document.getElementById('detectBtn').textContent = 
        isDetecting ? 'Detener Detección' : 'Iniciar Detección';
    }

    function clearTranslations() {
      translationsEl.innerHTML = '';
      lastDetection = '';
    }

    async function saveModel() {
      const dataset = classifier.getClassifierDataset();
      const datasetObj = {};
      Object.keys(dataset).forEach(key => {
        datasetObj[key] = Array.from(dataset[key].dataSync());
      });
      localStorage.setItem('gestureModel', JSON.stringify(datasetObj));
    }

    async function loadModel() {
      const savedModel = localStorage.getItem('gestureModel');
      if (savedModel) {
        const dataset = JSON.parse(savedModel);
        Object.keys(dataset).forEach(key => {
          const tensor = tf.tensor2d(dataset[key], [dataset[key].length / 63, 63]);
          classifier.addDataset(tensor, key);
        });
      }
    }
    
    camera.start();
    loadModel();
  </script>
</body>
</html>
