<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Detector de Señas Inteligente</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/knn-classifier"></script>
  <style>
    body {
      display: flex;
      flex-direction: column;
      align-items: center;
      margin: 0;
      padding: 20px;
      background: #f0f0f0;
      font-family: sans-serif;
    }
    #video, #overlay {
      position: absolute;
      top: 20px;
      left: 50%;
      transform: translateX(-50%) scaleX(-1);
      width: 640px;
      height: 480px;
    }
    #video { z-index: 1; }
    #overlay { 
      z-index: 2;
      pointer-events: none;
    }
    #message {
      margin-top: 520px;
      font-size: 1.5em;
      color: #333;
      text-align: center;
      width: 640px;
      white-space: pre-wrap;
    }
    .controls {
      margin: 10px;
      padding: 10px;
      z-index: 3;
    }
    input, button {
      padding: 8px;
      margin: 5px;
      font-size: 1em;
    }
    #progress {
      width: 300px;
      height: 20px;
      background: #ddd;
      margin: 10px;
      display: none;
    }
    #progress-bar {
      width: 0%;
      height: 100%;
      background: #4CAF50;
      transition: width 0.3s;
    }
    #detection-countdown {
      position: absolute;
      top: 50px;
      left: 50%;
      transform: translateX(-50%);
      font-size: 2em;
      color: red;
      z-index: 4;
      display: none;
    }
  </style>
</head>
<body>
  <h1>Detector de Señas Inteligente</h1>
  <div class="controls">
    <input type="text" id="gestureName" placeholder="Nombre del gesto">
    <button onclick="startTraining()">Agregar Gesto</button>
    <button onclick="toggleDetection()" id="detectBtn">Iniciar Detección</button>
  </div>
  <div id="progress">
    <div id="progress-bar"></div>
  </div>
  <div id="detection-countdown"></div>
  <video id="video" autoplay muted playsinline></video>
  <canvas id="overlay"></canvas>
  <div id="message"></div>

  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>

  <script>
    let classifier = knnClassifier.create();
    let isTraining = false;
    let isDetecting = false;
    let currentGesture = null;
    const detectedGestures = [];
    let trainingStartTime = 0;
    let progressInterval;
    let lastDetectionTime = 0;
    let detectionCoolDown = 3000;
    let currentDetection = null;
    let detectionConfidence = 0;
    let isCoolingDown = false;
    
    const videoElement = document.getElementById('video');
    const canvasElement = document.getElementById('overlay');
    const messageEl = document.getElementById('message');
    const progressBar = document.getElementById('progress-bar');
    const progressContainer = document.getElementById('progress');
    const detectBtn = document.getElementById('detectBtn');
    const countdownEl = document.getElementById('detection-countdown');

    canvasElement.width = 640;
    canvasElement.height = 480;
    const ctx = canvasElement.getContext('2d');

    const hands = new Hands({
      locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
    });
    
    hands.setOptions({
      maxNumHands: 1,
      modelComplexity: 1,
      minDetectionConfidence: 0.8,
      minTrackingConfidence: 0.7
    });

    hands.onResults(results => {
      ctx.clearRect(0, 0, canvasElement.width, canvasElement.height);
      ctx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);

      if (results.multiHandLandmarks) {
        results.multiHandLandmarks.forEach(landmarks => {
          window.drawConnectors(ctx, landmarks, window.HAND_CONNECTIONS, 
            {color: '#00FF00', lineWidth: 2});
          window.drawLandmarks(ctx, landmarks, {color: '#FF0000', lineWidth: 1});
        });

        if (isTraining || isDetecting) {
          processGesture(results.multiHandLandmarks[0]);
        }
      }
    });

    const camera = new Camera(videoElement, {
      onFrame: async () => await hands.send({ image: videoElement }),
      width: 640,
      height: 480
    });
    camera.start();

    async function processGesture(landmarks) {
      if (!isTraining && !isDetecting) return;
      
      const features = getNormalizedFeatures(landmarks);
      
      if (isTraining) {
        const elapsed = Date.now() - trainingStartTime;
        const progress = Math.min(elapsed / 3000 * 100, 100);
        progressBar.style.width = `${progress}%`;
        
        if (elapsed <= 3000) {
          classifier.addExample(tf.tensor2d(features, [1, 63]), currentGesture);
        }
      }
      
      if (isDetecting && !isCoolingDown) {
        const result = await classifier.predictClass(tf.tensor2d(features, [1, 63]));
        
        if (result.confidences[result.label] > 0.9) {
          if (result.label === currentDetection) {
            detectionConfidence++;
          } else {
            currentDetection = result.label;
            detectionConfidence = 1;
          }

          if (detectionConfidence >= 5) {
            handleConfirmedDetection(result.label);
          }
        } else {
          detectionConfidence = 0;
          currentDetection = null;
        }
      }
    }

    function getNormalizedFeatures(landmarks) {
      const wrist = landmarks[0];
      const relativeLandmarks = landmarks.map(l => ({
        x: l.x - wrist.x,
        y: l.y - wrist.y,
        z: l.z - wrist.z
      }));
      
      const maxVal = Math.max(
        ...relativeLandmarks.flatMap(l => [Math.abs(l.x), Math.abs(l.y), Math.abs(l.z)])
      );
      
      return relativeLandmarks.flatMap(l => [
        l.x / maxVal,
        l.y / maxVal,
        l.z / maxVal
      ]);
    }

    async function startTraining() {
      currentGesture = document.getElementById('gestureName').value.trim();
      if (!currentGesture) return alert('Ingresa un nombre para el gesto');
      
      const btn = document.querySelector('button[onclick="startTraining()"]');
      btn.disabled = true;
      detectBtn.disabled = true;
      document.getElementById('gestureName').value = '';
      
      messageEl.textContent = "Preparate: El entrenamiento comenzará en 3...";
      await countdown(3);
      
      progressContainer.style.display = 'block';
      progressBar.style.width = '0%';
      isTraining = true;
      trainingStartTime = Date.now();
      
      setTimeout(() => {
        isTraining = false;
        progressContainer.style.display = 'none';
        btn.disabled = false;
        detectBtn.disabled = false;
        messageEl.textContent = `${currentGesture} entrenado exitosamente!`;
        saveModel();
      }, 3000);
    }

    async function countdown(seconds) {
      return new Promise(resolve => {
        let count = seconds;
        const interval = setInterval(() => {
          messageEl.textContent = `Preparate: El entrenamiento comenzará en ${count}...`;
          count--;
          if (count < 0) {
            clearInterval(interval);
            resolve();
          }
        }, 1000);
      });
    }

    function toggleDetection() {
      isDetecting = !isDetecting;
      messageEl.textContent = isDetecting ? 
        'Modo detección activo - realiza un gesto' : 'Modo detección desactivado';
      detectBtn.textContent = isDetecting ? 'Detener Detección' : 'Iniciar Detección';
      detectedGestures.length = 0;
      updateMessage();
    }

    function handleConfirmedDetection(gesture) {
      if (Date.now() - lastDetectionTime < detectionCoolDown) return;
      
      isCoolingDown = true;
      lastDetectionTime = Date.now();
      detectedGestures.push(gesture);
      updateMessage();
      startDetectionCooldown();
    }

    function startDetectionCooldown() {
      let remaining = 3;
      countdownEl.style.display = 'block';
      
      const interval = setInterval(() => {
        countdownEl.textContent = `Próxima detección en: ${remaining}`;
        remaining--;
        
        if (remaining < 0) {
          clearInterval(interval);
          countdownEl.style.display = 'none';
          isCoolingDown = false;
          currentDetection = null;
          detectionConfidence = 0;
        }
      }, 1000);
    }

    function updateMessage() {
      messageEl.textContent = detectedGestures.length > 0 
        ? `Seña detectada: ${detectedGestures[detectedGestures.length - 1]}`
        : 'Ninguna seña detectada';
    }

    async function saveModel() {
      const dataset = classifier.getClassifierDataset();
      const datasetObj = {};
      Object.keys(dataset).forEach(key => {
        datasetObj[key] = Array.from(dataset[key].dataSync());
      });
      localStorage.setItem('gestureModel', JSON.stringify(datasetObj));
    }

    async function loadModel() {
      const savedModel = localStorage.getItem('gestureModel');
      if (savedModel) {
        const dataset = JSON.parse(savedModel);
        Object.keys(dataset).forEach(key => {
          const tensor = tf.tensor2d(dataset[key], [dataset[key].length / 63, 63]);
          classifier.addDataset(tensor, key);
        });
      }
    }
    
    loadModel();
  </script>
</body>
</html>
